<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>City Image Recognition</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Main</a>
					</header>

				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li class="active"><a href="index.html">Projects</a></li>
						<li><a href="about.html">About Me</a></li>
						<li><a href="contact.html">Contact</a></li>
						<li><a target="_blank" href="curry_resume_3_2020.pdf">Resume PDF</a></li>
					</ul>
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/michael-curry-7ab92118a/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://medium.com/@mdcurry1138" class="icon brands alt fa-medium"><span class="label">Medium</span></a></li>
						<li><a href="https://twitter.com/MikeDCurry" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://github.com/mikedcurry" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
					</ul>
				</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">

									<h1>Image Recognition Applied to City Photos<br /></h1>
								</header>
								<p> A CNN for image recognition is trained on results from Google Images API for 
									city names. The array of probabilities provided by a softmax output layer are 
									examined to determine subtle similarities between cities. The plans for a "City 
									Vibes" swiping app are here discussed.
								</p>
								<p>
									I started small with just nine photos between three cities. I put the photos 
									in folders in the same root directory as my project notebooks. Once I had 
									everything working on this micro-set, I went to work on pulling photos from the 
									google images API. After some searching, I came upon a fairly simple script that 
									allowed me to download multiple images from google for each city all at once. 
									https://github.com/hardikvasa/google-images-download
								</p>
                                <p><span class="image right"><img src="images\city_files.jpeg" alt="" /></span>

								<p>
									With my newly adopted script, I could fill my city folders with as many random 
									city photos as I specified. Again, I took the road of simplicity and only did 
									four photos for each of the 256 cities. Good thing I went small, because it took 
									me several hours to download these with my poor connection.
								</p>
                                <p>
									I decided to force all of my photos to be the same size. Maybe there is another 
									way of doing this, but figured that the input vectors were all going need to be 
									the same when they got plugged into the Neural Net. For this I used a prepossessing 
									tool from Keras. Again I started small with a resolution of 224 by 224 by 3 
									(for colors). I'm not sure if there is any reason for this size exactly, but I found 
									that a lot of instances of Keras use this exact size so I superstitiously followed 
									the apparent convention.
								</p>
								<!-- Preformatted Code -->
								<pre><code>from tensorflow.keras.preprocessing import image
def process_img_path(img_path): 
	return image.load_img(img_path, target_size=(224, 224))</code></pre>

								<p>
									Loading one of my photos to take a look:
								</p>

								<pre><code>image.load_img('./data/santa_fe/sfe1.jpg', target_size=(224,224))</code></pre>
								<p><span class="image left"><img src="images\city_sample_pic.png" alt="" /></span>

								<p>
									Then I wrote a short function to apply this size requirement to each photo as it adds 
									them as an array of values to a X vector.
								</p>
								<br>
								<br>
								<br>
								<br>
								<pre><code>data = []

for i in ['columbus', 'portland', 'santa_fe']:
	for file in os.listdir('./data/'+i):
	#         print(file) #to check if right files...
		if file[-3:] == 'jpg':
			path = os.path.join(f'./data/{i}/' + file)
			img = process_img_path(path)
			x = image.img_to_array(img)
			
			data.append(x)
	#             print(x)</code></pre>
								<p>
									For fun, we can take a peak at our vectorized photos:	
								</p>
								<p><span class="image left"><img src="images\city_vect_pic.png" alt="" /></span>
								
								<br>
								</br>
								<br>
								</br>
								<br>
								</br>
								<br>
								</br>
								<p>
									Taking a quick look at the shape of this array, shows us that we have 9 photos, each 
									being 224 by 224 pixles in 3 colors dimensions. Golden. Later the first number became 
									256 * n, the number of photos hosted per city.
								</p>
								<p><span class="image right"><img src="images\shape_array.png" alt="" /></span>
								<p>
									On my first attempt at creating a functional CNN, I created a simple target vector by
									 manually creating an array. Each number represented a city.
								</p>
								<pre><code>y = array([0, 0, 0, 1, 1, 1, 2, 2, 2])</code></pre>
								<p>For a bigger set of photos, I had to get a little more python savvy:</p>
								<pre><code># Create target vector

y = []
for i in range(0, 256):
j = [i]*4   # in this case 4 photos / city
for p in j:
	y.append(p)
y = np.asarray(y)</code></pre>
								<P>Writing something this simple that works is the quite satifying.</P>
								<p>y.shape yeilds:</p>
								<pre><code>array([ 0, 0, 0, …, 255, 255, 255])</code></pre>
								<p>Perfect, except that it needed to be made binary. For this purpose, 
									I used a quick Keras tool.
								</p>
								<pre><code>from keras.utils import to_categorical
y_binary = to_categorical(y)</code></pre>
								<p>Now our binary array represents the catagory, namely the city,
									as either a 0 or a 1 for each photo. For example, the first three lists within the 
									array start with 1 and the rest are zeros. Each of the first three lists seen 
									are photos of the first city and not any other. 
								</p>
								<pre><code>array([[1., 0., 0., ..., 0., 0., 0.],
	[1., 0., 0., ..., 0., 0., 0.],        
	[1., 0., 0., ..., 0., 0., 0.],        
		...,        
	[0., 0., 0., ..., 0., 0., 1.],        
	[0., 0., 0., ..., 0., 0., 1.],        
	[0., 0., 0., ..., 0., 0., 1.]], dtype=float32)</code></pre>
								<p>Next, I split my data into train and test. If I had a much bigger set, I would probably use a train/validate/test split, but this project primarily a proof of concept. Plus, I can't afford the computational power to run anything much bigger than four photos per city.</p>
								<pre><code>from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.25, stratify=y_binary)</code></pre>
								<p>In my "bigger" set with four photos for each 256 cities, I used three pics to train and one to test. Admittedly, this is not even remotely close to producing something that could be proven accurate, but that's not really the point of this project.</p>
								<p>I had a method for clearly defining my X and y vectors, now I needed to work out a model.</p>
								<hr />
								<p>I wanted to create a neural network that could take in my array of photos, use each city as a target, and output an array of probabilities that told how likely each photo was each city.</p>
								<p>After a lot of searching and digging, I found a number of very helpful articles 
									on building NNs with Keras from Jason Browlee  --  my current hero. Check out: 
									<a href = 'https://machinelearningmastery.com/category/deep-learning'>Deep Learning with Keras, J Brownlee.</a> 
									Seriously, this guy is fantastic!</p>
								<p>I also found some helpful information about how get an probabilities from a NN 
									using a softmax output layer and a categorical crossentropy loss function from 
									Haihan Lan -- <a href = https://towardsdatascience.com/the-softmax-function-neural-net-outputs-as-probabilities-and-ensemble-classifiers-9bd94d75932'>here</a>
									. This was the missing link I needed to use change the output of a neural network to an 
									array of probabilities as I was hoping for.
								</p>
								<p>After learning from these masters in my field, building my CNN model with a softmax output layer looks deceptively simple:</p>
								<pre><code>from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.models import Sequential, Model

#instantiate resnet50 & sew own a head -- input layer shape 
res = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)

# sew my tail on this beast
x1 = res.output
x1 = GlobalAveragePooling2D()(x1)
predictions = Dense(y_train[0].shape[0], activation='softmax')(x1)
model = Model(res.input, predictions)</code></pre>
								<p>Above, I've taken the absolutely beastly Resnet50 deep NN and simply sewed on my own input and output layers. I'm not going to pretend that I understand how the good folks at Mathworks dreamed up the layer structure of this deep neural net. However, I think it's worth taking a moment to appreciate what's under the hood on this model - prepare to scroll a ways. My model layers can be inspected using, model.summary:</p>




				<!-- Footer -->
				<footer id="footer">
						<section class="split contact">
							<section>
								<h3>Phone</h3>
								<p><a href="tel:+15757709143">(575) 770-9143</a></p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">mikecurry.ds@gmail.com</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/michael-curry-7ab92118a/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
									<li><a href="https://medium.com/@mdcurry1138" class="icon brands alt fa-medium"><span class="label">Medium</span></a></li>
									<li><a href="https://twitter.com/MikeDCurry" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="https://github.com/mikedcurry" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
					</section>
				</footer>

			<!-- Copyright -->
				<div id="copyright">
					<ul><li>Michael Curry</li><li>Data Scientist</li></ul>
				</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>